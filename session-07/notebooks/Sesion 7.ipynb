{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24d96d5",
   "metadata": {},
   "source": [
    "# üìò Sesi√≥n 7: Comparaci√≥n de Modelos e Introducci√≥n a Redes Neuronales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5336565",
   "metadata": {},
   "source": [
    "## üéØ Objetivo\n",
    "Comparar modelos supervisados e introducir redes neuronales simples con `MLPClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffdbb8",
   "metadata": {},
   "source": [
    "## üîç Carga de datos\n",
    "Usaremos el dataset `breast_cancer` de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7543da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc6091",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Preparaci√≥n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27cd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ba9ff",
   "metadata": {},
   "source": [
    "## üìä Comparaci√≥n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b6448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Exactitud promedio (cross-val): 0.955 ¬± 0.017\n",
      "Regresi√≥n Log√≠stica: Exactitud promedio (cross-val): 0.957 ¬± 0.006\n",
      "√Årbol de Decisi√≥n: Exactitud promedio (cross-val): 0.910 ¬± 0.029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Regresi√≥n Log√≠stica': LogisticRegression(max_iter=300),\n",
    "    '√Årbol de Decisi√≥n': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Exactitud promedio (cross-val): {scores.mean():.3f} ¬± {scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d14264-30df-4d38-bb14-69e00a78df23",
   "metadata": {},
   "source": [
    "### üìò Explicaci√≥n del c√≥digo\n",
    "\n",
    "- `from sklearn.neighbors import KNeighborsClassifier`, `LogisticRegression`, `DecisionTreeClassifier`:  \n",
    "  Se importan tres modelos supervisados cl√°sicos desde `scikit-learn` para comparaci√≥n.\n",
    "\n",
    "- `from sklearn.model_selection import cross_val_score`:  \n",
    "  Importa la funci√≥n que permite aplicar validaci√≥n cruzada a un modelo. Eval√∫a el desempe√±o promedio de un modelo entrenado y validado en m√∫ltiples particiones del conjunto de datos.\n",
    "\n",
    "- `models = { ... }`:  \n",
    "  Se define un diccionario con los tres modelos: KNN, regresi√≥n log√≠stica y √°rbol de decisi√≥n, cada uno instanciado con sus par√°metros por defecto (excepto `max_iter=300` en regresi√≥n log√≠stica para asegurar convergencia).\n",
    "\n",
    "- `for name, model in models.items()`:  \n",
    "  Itera sobre cada modelo definido para evaluarlo con la misma estrategia.\n",
    "\n",
    "- `cross_val_score(...)`:  \n",
    "  Ejecuta validaci√≥n cruzada con 5 particiones (`cv=5`) sobre los datos de entrenamiento. Se mide la `accuracy` en cada iteraci√≥n.\n",
    "\n",
    "- `scores.mean()`, `scores.std()`:  \n",
    "  Calcula el promedio y la desviaci√≥n est√°ndar de las 5 mediciones de exactitud obtenidas por la validaci√≥n cruzada.\n",
    "\n",
    "Este enfoque permite evaluar los modelos de forma justa, reduciendo el riesgo de sobreajuste a una sola divisi√≥n de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77fca5-a10e-4643-a3d2-fdaeab1a7779",
   "metadata": {},
   "source": [
    "### üìä An√°lisis de resultados de validaci√≥n cruzada\n",
    "\n",
    "| Modelo               | Exactitud promedio | Desviaci√≥n est√°ndar |\n",
    "|----------------------|--------------------|----------------------|\n",
    "| KNN                  | 0.955              | ¬± 0.017              |\n",
    "| Regresi√≥n Log√≠stica  | 0.957              | ¬± 0.006              |\n",
    "| √Årbol de Decisi√≥n    | 0.909              | ¬± 0.013              |\n",
    "\n",
    "- **KNN y Regresi√≥n Log√≠stica** muestran un rendimiento muy alto y similar en precisi√≥n promedio (~95.5%), con la regresi√≥n ligeramente mejor.\n",
    "- La **regresi√≥n log√≠stica** adem√°s tiene una **desviaci√≥n est√°ndar m√°s baja**, lo que indica que su desempe√±o es m√°s estable entre particiones del conjunto de datos.\n",
    "- El **√°rbol de decisi√≥n** tiene una exactitud promedio menor (90.9%) y una desviaci√≥n m√°s alta que la regresi√≥n, lo que sugiere mayor variabilidad y posiblemente m√°s sensibilidad a los datos de entrenamiento.\n",
    "\n",
    "**Conclusi√≥n:** En este conjunto de datos, tanto KNN como regresi√≥n log√≠stica generalizan bien, pero la regresi√≥n muestra m√°s consistencia. El √°rbol podr√≠a estar sobreajustando o no capturando adecuadamente la estructura de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66301898",
   "metadata": {},
   "source": [
    "## ü§ñ Introducci√≥n a redes neuronales (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdf2d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del MLPClassifier: 0.977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "mlp_score = mlp.score(X_test, y_test)\n",
    "print(f\"Exactitud del MLPClassifier: {mlp_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28350dfc-750d-497d-85ec-5bd6a286529c",
   "metadata": {},
   "source": [
    "### üìò Explicaci√≥n del c√≥digo\n",
    "\n",
    "- `from sklearn.neural_network import MLPClassifier`:  \n",
    "  Importa la clase `MLPClassifier`, que implementa un perceptr√≥n multicapa (red neuronal artificial) para tareas de clasificaci√≥n supervisada.\n",
    "\n",
    "- `mlp = MLPClassifier(...)`:  \n",
    "  Se crea un modelo de red neuronal con los siguientes par√°metros:\n",
    "  - `hidden_layer_sizes=(20,)`: se define una sola capa oculta con 20 neuronas.\n",
    "  - `activation='relu'`: se utiliza la funci√≥n de activaci√≥n ReLU, com√∫n en redes profundas por su eficiencia.\n",
    "  - `max_iter=1000`: se permite hasta 1000 iteraciones para que el modelo converja.\n",
    "  - `random_state=42`: se fija una semilla para reproducibilidad.\n",
    "\n",
    "- `mlp.fit(X_train, y_train)`:  \n",
    "  Entrena la red neuronal con los datos normalizados de entrenamiento. Durante el entrenamiento, la red ajusta los pesos y sesgos internos para minimizar el error de clasificaci√≥n.\n",
    "\n",
    "- `mlp.score(X_test, y_test)`:  \n",
    "  Calcula la exactitud del modelo sobre el conjunto de prueba, es decir, la proporci√≥n de predicciones correctas.\n",
    "\n",
    "- `print(...)`:  \n",
    "  Muestra la exactitud alcanzada por el modelo entrenado sobre datos no vistos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12676d",
   "metadata": {},
   "source": [
    "### üìä An√°lisis ampliado del resultado\n",
    "\n",
    "El modelo `MLPClassifier` alcanz√≥ una exactitud del **97.7%** sobre el conjunto de prueba. Este desempe√±o es superior al reportado por los modelos tradicionales comparados mediante validaci√≥n cruzada:\n",
    "\n",
    "- **KNN**: 95.5%\n",
    "- **Regresi√≥n log√≠stica**: 95.7%\n",
    "- **√Årbol de decisi√≥n**: 90.9%\n",
    "\n",
    "Aunque esta comparaci√≥n debe tomarse con precauci√≥n ‚Äîya que el MLP fue evaluado sobre una √∫nica partici√≥n de prueba (`test set`) mientras los otros modelos fueron evaluados con validaci√≥n cruzada (`cross_val`)‚Äî, el resultado sugiere que la red neuronal fue capaz de **capturar relaciones m√°s complejas** en los datos que los otros algoritmos no lograron modelar completamente.\n",
    "\n",
    "Este buen desempe√±o puede atribuirse a varias caracter√≠sticas de las redes neuronales:\n",
    "\n",
    "- Son capaces de **modelar no linealidades** de forma natural gracias a sus funciones de activaci√≥n no lineales.\n",
    "- Pueden **componer transformaciones internas** a trav√©s de m√∫ltiples capas, lo que les permite aprender representaciones jer√°rquicas de los datos.\n",
    "- El entrenamiento se realiza optimizando una funci√≥n de p√©rdida global, lo que favorece una soluci√≥n m√°s ajustada a la estructura de los datos.\n",
    "\n",
    "No obstante, las redes neuronales tambi√©n presentan **ciertas limitaciones importantes**:\n",
    "\n",
    "- Son modelos que requieren **m√°s tiempo de entrenamiento**, especialmente si el n√∫mero de capas o de neuronas es elevado.\n",
    "- Son **menos interpretables**, ya que no generan reglas claras ni coeficientes con sentido directo, como en la regresi√≥n log√≠stica o los √°rboles de decisi√≥n.\n",
    "- Son **sensibles a los hiperpar√°metros** y a la inicializaci√≥n, lo que hace necesario ajustar cuidadosamente valores como el n√∫mero de capas, el tama√±o de cada capa, el tipo de activaci√≥n o el algoritmo de optimizaci√≥n.\n",
    "\n",
    "Por estas razones, aunque el resultado obtenido es muy positivo, se recomienda complementar este an√°lisis con otras m√©tricas como la **precisi√≥n, recall, F1-score** y especialmente con la **matriz de confusi√≥n**, para verificar que el buen rendimiento global no oculte deficiencias graves en alguna de las clases (por ejemplo, un mal desempe√±o al identificar la clase minoritaria).\n",
    "\n",
    "Adem√°s, puede ser √∫til aplicar **validaci√≥n cruzada tambi√©n al MLPClassifier**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171cb220-ec4d-48dd-a50e-ff7c6801d3da",
   "metadata": {},
   "source": [
    "### ‚úÖ Conclusi√≥n\n",
    "\n",
    "El modelo `MLPClassifier` logr√≥ un desempe√±o superior en t√©rminos de exactitud (97.7%) frente a los modelos comparados previamente. Aunque esta cifra proviene de una evaluaci√≥n directa sobre el conjunto de prueba (y no de validaci√≥n cruzada), sugiere que la red neuronal fue capaz de modelar relaciones m√°s complejas en los datos.\n",
    "\n",
    "Esto resalta el potencial de las redes neuronales cuando existen patrones no lineales dif√≠ciles de capturar con modelos m√°s simples. Sin embargo, su implementaci√≥n tambi√©n implica desaf√≠os: mayor tiempo de entrenamiento, menor interpretabilidad y sensibilidad a la configuraci√≥n de hiperpar√°metros.\n",
    "\n",
    "Por tanto, si bien su rendimiento es prometedor, se recomienda validar su comportamiento con m√©tricas adicionales como F1-score, AUC y matriz de confusi√≥n. Tambi√©n ser√≠a ideal aplicar validaci√≥n cruzada para obtener una comparaci√≥n equitativa con los modelos previos y garantizar su estabilidad frente a nuevas particiones del conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bb531-a695-479e-ad0b-a31ac744ff52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
