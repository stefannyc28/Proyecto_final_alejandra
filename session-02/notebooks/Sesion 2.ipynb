{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb7e203",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n Predictiva antes y despu√©s de la Limpieza de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c1191",
   "metadata": {},
   "source": [
    "Este notebook tiene como objetivo comparar el desempe√±o de un modelo predictivo utilizando un conjunto de datos **antes y despu√©s** de aplicar una limpieza adecuada.\n",
    "\n",
    "Analizaremos el impacto de la imputaci√≥n, codificaci√≥n y escalado de variables, mostrando c√≥mo cada decisi√≥n afecta la calidad del modelo.\n",
    "\n",
    "La variable objetivo ser√° `Alta_conectividad`, una clasificaci√≥n binaria basada en el tiempo de uso de internet por d√≠a.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c37f23-7230-493a-bcca-e5abc925e2f2",
   "metadata": {},
   "source": [
    "# üß© Estudio de caso: Conectividad y bienestar social\n",
    "\n",
    "## üìò Contexto general\n",
    "\n",
    "La Fundaci√≥n Datos para el Progreso Social est√° trabajando en un programa que busca **mejorar el acceso a internet en comunidades vulnerables** de zonas urbanas y rurales. Para justificar futuras inversiones, el equipo de an√°lisis ha recolectado datos de **1.300 personas** a trav√©s de encuestas presenciales y registros administrativos.\n",
    "\n",
    "El objetivo es entender c√≥mo la **edad**, el **ingreso mensual**, el **nivel educativo** y el **uso diario de internet** se relacionan con la **posibilidad de acceder a oportunidades de formaci√≥n, empleo remoto o tr√°mites digitales**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Descripci√≥n del dataset\n",
    "\n",
    "El archivo `dataset_ejemplo_1300.csv` contiene las siguientes variables:\n",
    "\n",
    "| Variable            | Tipo          | Descripci√≥n |\n",
    "|---------------------|---------------|-------------|\n",
    "| `ID`                | Entero        | Identificador √∫nico por persona |\n",
    "| `Edad`              | Num√©rica      | Edad en a√±os |\n",
    "| `Ingreso`           | Num√©rica      | Ingreso mensual en pesos |\n",
    "| `Nivel_Educativo`   | Ordinal       | B√°sico, Medio, Superior |\n",
    "| `Genero`            | Categ√≥rica    | Hombre / Mujer |\n",
    "| `Horas_Internet`    | Num√©rica      | Promedio de horas de uso diario de internet |\n",
    "| `Ciudad`            | Categ√≥rica    | Nombre de la ciudad de residencia |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Problema a resolver\n",
    "\n",
    "Antes de construir un modelo predictivo que clasifique si una persona tiene alta conectividad (por ejemplo, m√°s de 3.5 horas al d√≠a en internet), **es fundamental preparar los datos adecuadamente**.\n",
    "\n",
    "El dataset presenta varios desaf√≠os:\n",
    "- **Valores faltantes** en ingresos y edad.\n",
    "- **Codificaci√≥n no num√©rica** en g√©nero y nivel educativo.\n",
    "- **Posibles duplicados o inconsistencias** por errores en captura manual.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß ¬øQu√© haremos en esta sesi√≥n?\n",
    "\n",
    "Aplicaremos un flujo de trabajo de limpieza de datos inspirado en la metodolog√≠a **CRISP-DM**, espec√≠ficamente en la etapa de *Preparaci√≥n de los Datos*. Vamos a:\n",
    "\n",
    "1. Diagnosticar problemas comunes en el dataset.\n",
    "2. Imputar valores faltantes.\n",
    "3. Codificar variables categ√≥ricas.\n",
    "4. Eliminar duplicados.\n",
    "5. Generar una versi√≥n limpia y lista para modelar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8596bfd",
   "metadata": {},
   "source": [
    "## 1. Cargar el dataset y crear variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58983f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Genero</th>\n",
       "      <th>Ingreso</th>\n",
       "      <th>Nivel_Educativo</th>\n",
       "      <th>Horas_Internet</th>\n",
       "      <th>Ciudad</th>\n",
       "      <th>CodigoID</th>\n",
       "      <th>Alta_conectividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Femenino</td>\n",
       "      <td>4842.42</td>\n",
       "      <td>Secundaria</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Cali</td>\n",
       "      <td>1-Cal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>5742.02</td>\n",
       "      <td>Posgrado</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Medell√≠n</td>\n",
       "      <td>2-Med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Otro</td>\n",
       "      <td>4335.12</td>\n",
       "      <td>T√©cnico</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Villavicencio</td>\n",
       "      <td>3-Vil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Otro</td>\n",
       "      <td>4515.57</td>\n",
       "      <td>Tecn√≥logo</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Bogot√°</td>\n",
       "      <td>4-Bog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Otro</td>\n",
       "      <td>3846.49</td>\n",
       "      <td>Primaria</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Pasto</td>\n",
       "      <td>5-Pas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Edad     Genero  Ingreso Nivel_Educativo  Horas_Internet  \\\n",
       "0   1  22.0   Femenino  4842.42      Secundaria             1.6   \n",
       "1   2  47.0  Masculino  5742.02        Posgrado             5.6   \n",
       "2   3  38.0       Otro  4335.12         T√©cnico             2.3   \n",
       "3   4  17.0       Otro  4515.57       Tecn√≥logo             3.2   \n",
       "4   5  28.0       Otro  3846.49        Primaria             1.3   \n",
       "\n",
       "          Ciudad CodigoID  Alta_conectividad  \n",
       "0           Cali    1-Cal                  0  \n",
       "1       Medell√≠n    2-Med                  1  \n",
       "2  Villavicencio    3-Vil                  0  \n",
       "3         Bogot√°    4-Bog                  0  \n",
       "4          Pasto    5-Pas                  0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df_raw = pd.read_csv('../../datos/dataset_ejemplo_1300.csv')\n",
    "\n",
    "# Crear variable objetivo: Alta conectividad\n",
    "df_raw[\"Alta_conectividad\"] = (df_raw[\"Horas_Internet\"] > 3.5).astype(int)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2cc36b-cd03-4be9-bfdc-4bf35543c40f",
   "metadata": {},
   "source": [
    "### üìò Explicaci√≥n del c√≥digo\n",
    "\n",
    "- `import pandas as pd`:  \n",
    "  Importa la librer√≠a `pandas`, usada para manipular datos en formato tabular.\n",
    "\n",
    "- `pd.read_csv(...)`:  \n",
    "  Carga el archivo CSV y lo convierte en un DataFrame llamado `df_raw`, que es una tabla de datos que permite filtrado, estad√≠sticas, etc.\n",
    "\n",
    "- `df_raw[\"Alta_conectividad\"] = ...`:  \n",
    "  Crea una nueva columna llamada `Alta_conectividad`, que ser√° nuestra **variable objetivo**:\n",
    "  - Asigna el valor `1` si la persona usa m√°s de 3.5 horas diarias de internet.\n",
    "  - Asigna el valor `0` en caso contrario.\n",
    "  - Se convierte el resultado booleano en entero con `.astype(int)`.\n",
    "\n",
    "- `df_raw.head()`:  \n",
    "  Muestra las primeras 5 filas del DataFrame, √∫til para verificar que la carga de datos fue exitosa y que la nueva columna fue creada correctamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db832c",
   "metadata": {},
   "source": [
    "## 2. Evaluaci√≥n del modelo antes de limpiar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0907ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exactitud antes de la limpieza: 0.5778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Usamos solo Edad e Ingreso, eliminando nulos\n",
    "df_before = df_raw[[\"Edad\", \"Ingreso\"]].dropna()\n",
    "Xb = df_before\n",
    "yb = df_raw.loc[df_before.index, \"Alta_conectividad\"]\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.3, random_state=42)\n",
    "\n",
    "model_before = LogisticRegression(max_iter=200)\n",
    "model_before.fit(Xb_train, yb_train)\n",
    "yb_pred = model_before.predict(Xb_test)\n",
    "acc_before = accuracy_score(yb_test, yb_pred)\n",
    "\n",
    "print(\"‚úÖ Exactitud antes de la limpieza:\", round(acc_before, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cfe3b6-6c8b-4c93-8e4b-ee77a72001da",
   "metadata": {},
   "source": [
    "### Explicaci√≥n detallada del bloque de c√≥digo: modelo antes de la limpieza\n",
    "\n",
    "Este bloque eval√∫a el rendimiento de un modelo de regresi√≥n log√≠stica antes de realizar cualquier tipo de limpieza, escalado o codificaci√≥n de datos. Se trabaja √∫nicamente con las columnas `Edad` e `Ingreso`, eliminando registros con datos faltantes. El objetivo es establecer una l√≠nea base para comparar con el modelo que se construir√° despu√©s de preparar los datos correctamente.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Usamos solo Edad e Ingreso, eliminando nulos\n",
    "df_before = df_raw[[\"Edad\", \"Ingreso\"]].dropna()\n",
    "Xb = df_before\n",
    "yb = df_raw.loc[df_before.index, \"Alta_conectividad\"]\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(Xb, yb, test_size=0.3, random_state=42)\n",
    "\n",
    "model_before = LogisticRegression(max_iter=200)\n",
    "model_before.fit(Xb_train, yb_train)\n",
    "yb_pred = model_before.predict(Xb_test)\n",
    "acc_before = accuracy_score(yb_test, yb_pred)\n",
    "\n",
    "print(\"‚úÖ Exactitud antes de la limpieza:\", round(acc_before, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60faf48b-85c3-4895-a6df-34bb1d20a1c9",
   "metadata": {},
   "source": [
    "### ¬øQu√© significa este resultado?\n",
    "\n",
    "`Exactitud antes de la limpieza: 0.5778`\n",
    "\n",
    "Este valor indica que el modelo de regresi√≥n log√≠stica logr√≥ una **exactitud del 57.78%** al predecir si una persona tiene o no alta conectividad, utilizando √∫nicamente las variables `Edad` e `Ingreso`, y **sin aplicar limpieza, imputaci√≥n o transformaci√≥n de los datos**.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øQu√© es la exactitud?\n",
    "\n",
    "La **exactitud (accuracy)** es una m√©trica de evaluaci√≥n que indica qu√© proporci√≥n de predicciones del modelo fueron correctas. Se calcula as√≠:\n",
    "\n",
    "**Exactitud = predicciones correctas / total de predicciones**\n",
    "\n",
    "En este caso, el modelo acert√≥ en aproximadamente **58 de cada 100 predicciones**.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øC√≥mo interpretar este valor?\n",
    "\n",
    "- El modelo tiene un rendimiento **b√°sico o limitado**.\n",
    "- Aunque supera el azar (50% si las clases est√°n balanceadas), a√∫n est√° lejos de ser un modelo confiable.\n",
    "- Esto sugiere que el modelo **no est√° capturando patrones relevantes en los datos**.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øPor qu√© la exactitud es baja?\n",
    "\n",
    "- Solo se usaron dos variables (`Edad` e `Ingreso`).\n",
    "- Se eliminaron filas con valores faltantes (`dropna()`), lo que **reduce el tama√±o de la muestra**.\n",
    "- No se aplic√≥ ning√∫n tipo de **escalado**, **codificaci√≥n de variables categ√≥ricas**, ni **imputaci√≥n de valores**.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øPara qu√© sirve este resultado?\n",
    "\n",
    "Este resultado act√∫a como una **l√≠nea base**.  \n",
    "Servir√° como referencia para comparar con un segundo modelo entrenado despu√©s de aplicar t√©cnicas de preparaci√≥n de datos.  \n",
    "Si ese segundo modelo obtiene una mayor exactitud, podremos concluir que **la preparaci√≥n de datos mejora la capacidad predictiva del modelo**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc39197e",
   "metadata": {},
   "source": [
    "## 3. Preparaci√≥n del dataset: limpieza, imputaci√≥n y codificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fde304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# Imputaci√≥n\n",
    "imputer_edad = SimpleImputer(strategy='median')\n",
    "df_clean['Edad'] = imputer_edad.fit_transform(df_clean[['Edad']])\n",
    "\n",
    "imputer_ingreso = SimpleImputer(strategy='mean')\n",
    "df_clean['Ingreso'] = imputer_ingreso.fit_transform(df_clean[['Ingreso']])\n",
    "\n",
    "# Codificaci√≥n de variables categ√≥ricas\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Genero', 'Nivel_Educativo', 'Ciudad'], drop_first=True)\n",
    "\n",
    "# Escalado\n",
    "scaler = MinMaxScaler()\n",
    "df_clean[['Edad', 'Ingreso']] = scaler.fit_transform(df_clean[['Edad', 'Ingreso']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96810c96-04ec-4f76-ac17-248dc13addfe",
   "metadata": {},
   "source": [
    "### üßº Limpieza y preparaci√≥n del dataset\n",
    "\n",
    "- `from sklearn.impute import SimpleImputer`:  \n",
    "  Importa la clase `SimpleImputer` para rellenar valores faltantes en columnas num√©ricas.\n",
    "\n",
    "- `from sklearn.preprocessing import MinMaxScaler`:  \n",
    "  Importa el escalador `MinMaxScaler` para normalizar valores entre 0 y 1.\n",
    "\n",
    "- `df_clean = df_raw.copy()`:  \n",
    "  Crea una copia del DataFrame original para no modificar los datos en bruto.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîß Imputaci√≥n de valores faltantes\n",
    "\n",
    "- `SimpleImputer(strategy='median')`:  \n",
    "  Crea un imputador que reemplaza los valores nulos en la variable `Edad` por la mediana de la columna.\n",
    "\n",
    "- `SimpleImputer(strategy='mean')`:  \n",
    "  Reemplaza los valores nulos en la variable `Ingreso` por la media de la columna.\n",
    "\n",
    "> Se utiliza `.fit_transform(...)` para ajustar el imputador y aplicar la transformaci√≥n directamente.\n",
    "\n",
    "---\n",
    "\n",
    "#### üè∑Ô∏è Codificaci√≥n de variables categ√≥ricas\n",
    "\n",
    "- `pd.get_dummies(..., drop_first=True)`:  \n",
    "  Convierte las variables categ√≥ricas (`Genero`, `Nivel_Educativo`, `Ciudad`) en variables binarias usando codificaci√≥n *one-hot*.  \n",
    "  La opci√≥n `drop_first=True` elimina una categor√≠a por cada variable para evitar colinealidad.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìè Escalado de variables num√©ricas\n",
    "\n",
    "- `MinMaxScaler()`:  \n",
    "  Escala los valores de `Edad` e `Ingreso` entre 0 y 1, lo cual es √∫til para algoritmos sensibles a la magnitud de los datos (como KNN o regresi√≥n log√≠stica).\n",
    "\n",
    "- `scaler.fit_transform(...)`:  \n",
    "  Ajusta el escalador a los datos y transforma simult√°neamente los valores.\n",
    "\n",
    "---\n",
    "\n",
    "El resultado final es un DataFrame `df_clean` sin valores nulos, con variables categ√≥ricas codificadas y variables num√©ricas escaladas, listo para usar en un modelo predictivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25569b",
   "metadata": {},
   "source": [
    "## 4. Evaluaci√≥n del modelo despu√©s de la limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3e0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exactitud despu√©s de la limpieza: 0.6205\n"
     ]
    }
   ],
   "source": [
    "Xc = df_clean.drop(columns=['ID', 'CodigoID', 'Horas_Internet', 'Alta_conectividad'])\n",
    "yc = df_clean['Alta_conectividad']\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.3, random_state=42)\n",
    "\n",
    "model_after = LogisticRegression(max_iter=200)\n",
    "model_after.fit(Xc_train, yc_train)\n",
    "yc_pred = model_after.predict(Xc_test)\n",
    "acc_after = accuracy_score(yc_test, yc_pred)\n",
    "\n",
    "print(\"‚úÖ Exactitud despu√©s de la limpieza:\", round(acc_after, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4dc29-5b16-43c2-b236-f93f4d0cdd5d",
   "metadata": {},
   "source": [
    "### ü§ñ Modelado con datos limpios ‚Äì Regresi√≥n log√≠stica\n",
    "\n",
    "- `Xc = df_clean.drop(columns=['ID', 'CodigoID', 'Horas_Internet', 'Alta_conectividad'])`:  \n",
    "  Se seleccionan como variables predictoras (`Xc`) todas las columnas del dataset limpio excepto identificadores, la variable a predecir (`Alta_conectividad`) y la columna `Horas_Internet` (que se us√≥ para crear la variable objetivo).\n",
    "\n",
    "- `yc = df_clean['Alta_conectividad']`:  \n",
    "  Define la variable objetivo (`yc`), es decir, lo que se quiere predecir: si una persona tiene o no alta conectividad.\n",
    "\n",
    "---\n",
    "\n",
    "#### üì¶ Divisi√≥n del dataset\n",
    "\n",
    "- `train_test_split(...)`:  \n",
    "  Se divide el conjunto de datos en entrenamiento (70%) y prueba (30%) usando una semilla aleatoria fija (`random_state=42`) para garantizar resultados reproducibles.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîç Entrenamiento del modelo\n",
    "\n",
    "- `LogisticRegression(max_iter=200)`:  \n",
    "  Se crea un modelo de regresi√≥n log√≠stica para clasificaci√≥n binaria. El par√°metro `max_iter=200` define el n√∫mero m√°ximo de iteraciones para ajustar el modelo si los datos son complejos.\n",
    "\n",
    "- `model_after.fit(Xc_train, yc_train)`:  \n",
    "  Se entrena el modelo con los datos de entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Predicci√≥n y evaluaci√≥n\n",
    "\n",
    "- `yc_pred = model_after.predict(Xc_test)`:  \n",
    "  El modelo genera predicciones para el conjunto de prueba.\n",
    "\n",
    "- `accuracy_score(yc_test, yc_pred)`:  \n",
    "  Se calcula la **exactitud** del modelo: la proporci√≥n de predicciones correctas sobre el total.\n",
    "\n",
    "- `print(...)`:  \n",
    "  Imprime en pantalla la exactitud obtenida redondeada a 4 cifras decimales.\n",
    "\n",
    "---\n",
    "\n",
    "Este bloque permite evaluar el impacto de la limpieza sobre el rendimiento del modelo. Una mayor exactitud respecto al modelo sin limpiar indica que la preparaci√≥n de datos fue beneficiosa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab4ee8-7a25-4e36-a6f8-e97282fe681b",
   "metadata": {},
   "source": [
    "### ¬øQu√© significa este resultado?\n",
    "\n",
    "`Exactitud despu√©s de la limpieza: 0.6205`\n",
    "\n",
    "Este valor indica que el modelo de regresi√≥n log√≠stica logr√≥ una **exactitud del 62.05%** al predecir si una persona tiene o no alta conectividad, utilizando un conjunto de datos que fue previamente **preparado y limpiado**.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øQu√© se hizo antes de este resultado?\n",
    "\n",
    "Antes de entrenar este modelo, se aplicaron varias t√©cnicas de **preparaci√≥n de datos**:\n",
    "\n",
    "- **Imputaci√≥n de valores faltantes**:  \n",
    "  Se reemplazaron los valores nulos en `Edad` con la mediana y en `Ingreso` con la media.\n",
    "\n",
    "- **Codificaci√≥n de variables categ√≥ricas**:  \n",
    "  Se transformaron las variables como `G√©nero`, `Nivel_Educativo` y `Ciudad` en variables num√©ricas usando `one-hot encoding`.\n",
    "\n",
    "- **Escalado de variables num√©ricas**:  \n",
    "  `Edad` e `Ingreso` fueron normalizadas con **Min-Max Scaling** para que est√©n en la misma escala (entre 0 y 1).\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øPor qu√© mejor√≥ la exactitud?\n",
    "\n",
    "- El modelo ahora tiene acceso a **m√°s informaci√≥n √∫til**, no solo `Edad` e `Ingreso`.\n",
    "- Se retuvieron registros con datos faltantes gracias a la **imputaci√≥n**, evitando la p√©rdida de datos.\n",
    "- Las variables categ√≥ricas est√°n representadas num√©ricamente, lo que mejora la capacidad del modelo para identificar patrones.\n",
    "- El escalado garantiza que ninguna variable domine por su magnitud.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øC√≥mo interpretar este valor?\n",
    "\n",
    "- Una exactitud del **62.05%** es **superior al modelo anterior** (57.78%), aunque no representa una mejora extrema.\n",
    "- La diferencia muestra que preparar los datos **tiene un impacto positivo**, pero tambi√©n que el modelo puede beneficiarse a√∫n m√°s con t√©cnicas adicionales o mejores variables.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øPor qu√© es importante esta comparaci√≥n?\n",
    "\n",
    "Comparar este resultado con el obtenido antes de la limpieza permite **cuantificar el impacto real de preparar bien los datos**.  \n",
    "Aunque la mejora no es dr√°stica, demuestra que **incluso mejoras modestas pueden hacer que el modelo sea m√°s confiable**.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusi√≥n\n",
    "\n",
    "El modelo despu√©s de la limpieza supera en precisi√≥n al modelo inicial.  \n",
    "Esto valida que **limpiar, imputar, codificar y escalar adecuadamente los datos mejora el rendimiento predictivo**, y es una parte cr√≠tica del proceso de an√°lisis predictivo.\n",
    "\n",
    "La comparaci√≥n entre ambos enfoques demuestra c√≥mo una limpieza adecuada mejora la capacidad del modelo para generalizar.\n",
    "\n",
    "Antes de la limpieza: solo dos variables, filas eliminadas por nulos.\n",
    "Despu√©s de la limpieza: m√°s variables, nulos imputados, todo escalado\n",
    "Esta diferencia se refleja directamente en la exactitud del modelo.\n",
    "\n",
    "üëâ Las decisiones de preparaci√≥n de datos son tan importantes como el modelo mismo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
